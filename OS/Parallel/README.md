# Parallel (병렬성)

- 병렬프로그래밍에서 Memory Map이 어떤식으로 돌아가는지 정확히 알아야 이해가 쉬워진다

## [Memory Map](https://www.youtube.com/watch?v=QSjYfbu2zZ8)

### Single thread

- Stack
    - 로컬 변수
- Heap
    - 벡터
    - 힙에 할당하고 로컬변수가 가리킨다
- Static Data
- Code
    - 머신 코드가 쌓여있고 프로그램 카운트가 처음 이부분을 시작하면서 프로그래밍에 맞춰서 하나씩 순차적으로 넘어가는 개념

### Multi thread

- Stack
    - 로컬 변수
    - thread #1 이 관리하는 스택에서는 로컬 변수들이 stack#1 에 생긴다
    - 다른 쓰레드에서는 로컬 변수를 공유할수 없다.(쓰레드에 종속적)
- Heap
    - 또 다른 메모리를 사용 가능
    - 힙과 스태틱 공간은 공유를 한다.
    - 여러 스레드에서 하나의 힙이나 스태틱 메모리에 접근하면서 각자의 연산을 하면 `Race Condition` 이 생기면서 결과의 값을 맞다고 보장할수 없다.
        - Race Condition
            - Atomic
            - Mutext
- Static Data
    - 힙과 스태틱 공간은 공유를 한다.
- Code
    - thread 가 새로 생기면 프로그램 카운터가 새로운 파트를 시작

---

## [Race Condition](https://www.youtube.com/watch?v=VxINGM7V2sg)

- 어떤 쓰레드가 먼저 연산을 끝내야하는지에 대한 정의가 없기 때문에 일어나는것을 Race Condition 이라고 한다.
- 병렬 프로그래밍에서 스레드가 하나의 공간에 동시에 읽고 쓰는 작업을 하면 read, write 를 할때 값이 변경되었는지 안되었는지 보장할수 없고 정확하지 않기 때문에 연산이나 값이 누락이 되는 현상
- 병렬 프로그래밍에서 가속을 했을때 언제 일어날수 있는가?
    - 벡터 `nums` 10000개 loop로 sum 을 구한다고 했을때 sum 이 글로벌 변수로 지정되어 있을때 sum을 병렬 프로그래밍으로 loop 를 나누게 되면 `Race Condition` 이 일어나게 된다.

- 메모리맵
    - Stack
        - 벡터 nums
    - Heap
        - 10000 개의 Array 를 가지고 nums 가 이를 가리킨다.
        - 병렬 프로그래밍이라고 하면 Array 가 5000 개씩 2개로 나눠지고 각각 sum 을 시작
        - 2개의 스레드가 동시에 sum 에 num 을 더하는 연산과정을 하기 위해 2개 스레드가 동시에 글로벌 변수에 접근하기 시작
        - 2개의 스레드가 하나의 공간에 쓰기 작업을 시작하기 때문에 Race Condition 이 일어날수 있다.
    - Data Section
        - 글로벌 변수 sum이 선언되어 있음

### 해결 방법

- `mutex lock`
- `atomic`
- `결과값을 split`
    - sum을 2개로 나눠서 사용
    - 10000개를 반으로 나누고 각각을 다른 sum1, sum2 변수에 결과값을 계산
    - sum1, sum2 를 합쳐서 하나의 결과값으로 사용
    - 이렇게 하면 병렬 프로그래밍이지만 싱글코어로 계산한것보다 계산 자체가 느려지는데 이것을 `False Sharing` 이라고 한다.

---

## [False Sharing](https://www.youtube.com/watch?v=SbaiAQDUi9A)

- 어떤 상황때문에 병렬 프로그래밍이 더 느릴수도 있다
- 컴퓨터 구조때문에 발생
    - CPU
        - 각각의 코어에는 개별적으로 L1/L2 캐시가 존재
        - L3 캐시 모든 코어가 공유를 하는 시스템으로 되어있음
        - 각 코어는 64바이트를 가지고오는데 이 64바이트(캐시라인)안에 sums(예를 들어 합계 변수) 라는 부분이 각각 4개의 공간에 존재
        - 각각의 쓰레드는 각각의 연산을 한다고 가정하면 각 코어의 할당된 공간에 연산을 하고 있을것이다.
            - **레이스 컨디션을 없애기 위해 각각의 할당된 곳에만 계산을 한다고 하고 프로그래밍을 했지만 실제로 물리적으로 각각의 코어마다 캐시라인의 상태가 달라서 잘못 쉐어링을 하고 있다고 해서 False Sharing 이라고 한다.**
            - **논리적인 상태로는 항상 같은 값을 가져야하지만 물리적으로는 다르기 때문에 CPU 는 False 한 쉐어링 상태를 없애기위해 캐시라인끼리 싱크 프로세스를 진행해서 논리적인 상태와 물리적인 상태를 똑같이 맞춰준다.**
            - **싱크 프로세스때문에 각각의 스레드가 계산을 해야하는데 하다가 멈추고 싱크, 계산하다가 싱크하는 작업을 반복하므로 병렬 프로그래밍이 더 느려진다.**
    - 하드웨어 캐시
        - L1 캐시는 따로 가지고 있다.
        - Cache Line
            - 현재 모던 x86 x64 아키텍처의 캐시라인 사이즈는 64바이트
            - 하나의 코어에서 어떤 데이터를 액세스 할때 메모리 구조상 64바이트가 동시에 딸려온다
- 해결 방법
    - Padding 솔루션
        - sums 를 16바이트를 사용해서 계산하는데 이 공간을 길게 잡아주고 이 공간을 4개로 분리 (64바이트가 되도록)
        - 각각의 쓰레드가 이 분리된 공간에 계산을 하고 나머지 64바이트를 채울 공간에 padding(쓰레기값) 으로 채워준다.
    - [Mutex Concurrency(동시성)](./../Concurrency)